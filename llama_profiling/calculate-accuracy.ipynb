{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f65bf37-ded4-47f5-84f2-57e1794d13a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# BASE_DIR = \"../llama_profiling/experiments/llama_profiling\"\n",
    "# OUTPUT_FILE = \"merged_energibridge.csv\"\n",
    "\n",
    "# csv_files = [\n",
    "#     os.path.join(root, f)\n",
    "#     for root, _, files in os.walk(BASE_DIR)\n",
    "#     for f in files if f.endswith(\".csv\")\n",
    "# ]\n",
    "\n",
    "# dfs = []\n",
    "# for path in csv_files:\n",
    "#     df = pd.read_csv(path)\n",
    "#     df.columns = df.columns.str.strip()\n",
    "#     dfs.append(df)\n",
    "\n",
    "# merged = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# merged.to_csv(OUTPUT_FILE, index=False)\n",
    "# print(f\"Merged CSV saved: {OUTPUT_FILE}\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b782a80-5945-4ac0-bdc3-60c1d28eaca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8df856a6-1c3f-4c63-80f4-8d5ac51f1fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ../llama_profiling/experiments/llama_profiling\\run_0_repetition_0\\energibridge.csv\n",
      "    accuracy\n",
      "0        NaN\n",
      "1        NaN\n",
      "2        NaN\n",
      "3        NaN\n",
      "4        NaN\n",
      "5        NaN\n",
      "6        NaN\n",
      "7        NaN\n",
      "8        NaN\n",
      "9        NaN\n",
      "10       NaN\n",
      "11       NaN\n",
      "12       NaN\n",
      "13       NaN\n",
      "14       NaN\n",
      "15       NaN\n",
      "16       NaN\n",
      "17       NaN\n",
      "18       NaN\n",
      "19       NaN\n",
      "20       NaN\n",
      "21       NaN\n",
      "22       1.0\n",
      "23       NaN\n",
      "24       NaN\n",
      "25       NaN\n",
      "26       NaN\n",
      "27       0.5\n",
      "28       NaN\n",
      "29       NaN\n",
      "30       NaN\n",
      "31       NaN\n",
      "32       NaN\n",
      "33       NaN\n",
      "34       NaN\n",
      "35       NaN\n",
      "36       NaN\n",
      "37       NaN\n",
      "38       NaN\n",
      "39       NaN\n",
      "40       NaN\n",
      "41       NaN\n",
      "42       NaN\n",
      "43       NaN\n",
      "44       NaN\n",
      "45       NaN\n",
      "46       1.0\n",
      "47       NaN\n",
      "48       NaN\n",
      "49       NaN\n",
      "50       1.0\n",
      "51       NaN\n",
      "52       NaN\n",
      "53       NaN\n",
      "54       1.0\n",
      "55       NaN\n",
      "56       NaN\n",
      "57       NaN\n",
      "58       NaN\n",
      "59       NaN\n",
      "60       NaN\n",
      "61       NaN\n",
      "62       NaN\n",
      "63       NaN\n",
      "64       NaN\n",
      "65       NaN\n",
      "66       NaN\n",
      "67       NaN\n",
      "68       NaN\n",
      "69       NaN\n",
      "70       NaN\n",
      "71       NaN\n",
      "72       NaN\n",
      "73       NaN\n",
      "74       NaN\n",
      "75       NaN\n",
      "76       NaN\n",
      "77       NaN\n",
      "78       NaN\n",
      "79       NaN nan\n",
      "Finished, output to file out.csv\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = \"../llama_profiling/experiments/llama_profiling\"\n",
    "OUTPUT_FILE = \"merged_energibridge.csv\"\n",
    "\n",
    "csv_files = [\n",
    "    os.path.join(root, f)\n",
    "    for root, _, files in os.walk(BASE_DIR)\n",
    "    for f in files if f.endswith(\".csv\")\n",
    "][1:2]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "results = []\n",
    "\n",
    "run_table_pd = pd.read_csv('../llama_profiling/experiments/llama_profiling/run_table.csv')\n",
    "\n",
    "\n",
    "def split_run_id(val):\n",
    "    # Search for patterns like \"run_0_repetition_0\" or \"run0_repetition0\"\n",
    "    match = re.search(r'run_?(\\d+)_+repetition_?(\\d+)', val)\n",
    "    if match:\n",
    "        run_num, repetition_num = match.groups()\n",
    "        return run_num, repetition_num\n",
    "    return None, None\n",
    "    \n",
    "for i,path in enumerate(csv_files):\n",
    "    folder = path[:path.rfind(\"\\\\\")]\n",
    "    #if 'run_0_repetition_15' not in path:\n",
    "    #    print('ignoring', path)\n",
    "    #    continue\n",
    "\n",
    "    print('running', path)\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    \n",
    "    # .tsv data\n",
    "    tsv_df = pd.read_csv(folder+\"\\\\prompts_out.tsv\", sep=\"\\t\")\n",
    "    \n",
    "    tsv_df['prompt_length'] = tsv_df[\"prompt\"].str.len()\n",
    "    tsv_df['response_length'] = tsv_df[\"response\"].str.len()\n",
    "    \n",
    "    timestamp_start_prompts, timestamp_end_prompts = tsv_df.iloc[0]['start'], tsv_df.iloc[-1]['end']\n",
    "\n",
    "    # Filter out the rows that're wihin the execution window (skipping engine initialization). 1000 is due to UNIX timestamp granularity\n",
    "    df = df[(df['Time'] / 1000 >= timestamp_start_prompts) & (df['Time']  / 1000 <= timestamp_end_prompts)]\n",
    "        \n",
    "    # Fix overflow and normalize to energy_diff\n",
    "    diff = df[\"PACKAGE_ENERGY (J)\"] - df[\"PACKAGE_ENERGY (J)\"].shift(1)\n",
    "    df[\"energy_diff\"] = np.where(diff < 0, df[\"PACKAGE_ENERGY (J)\"], diff.fillna(0))\n",
    "    \n",
    "    # Calculate GPU consumption\n",
    "    df[\"gpu_joules\"] = df[\"GPU0_POWER (mWatts)\"] / 5000 + df[\"energy_diff\"]\n",
    "\n",
    "    # Display all rows\n",
    "    #with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    #    print(df[[\"gpu_joules\", \"PACKAGE_ENERGY (J)\"]], )\n",
    "        \n",
    "    # Total consumption\n",
    "    energy_consumption_total=sum(df[\"gpu_joules\"]) + sum(df[\"energy_diff\"])\n",
    "    \n",
    "    run, rep = split_run_id(path)\n",
    "    \n",
    "    row = {\n",
    "        \"run\": run,\n",
    "        \"rep\": rep,\n",
    "        \"duration_ms\": df.iloc[-1]['Time']-df.iloc[0]['Time'],\n",
    "        \"cpu_joules\": sum(df[\"energy_diff\"]),\n",
    "        \"gpu_joules\": sum(df[\"gpu_joules\"]),\n",
    "        \"energy_consumption_total_joules\": energy_consumption_total,\n",
    "        \"response_length_sum_characters\": sum(tsv_df['response_length']),\n",
    "        \"response_token_count\": sum(tsv_df['response_tokens']),\n",
    "        \"accuracy\": sum(tsv_df['accuracy']) / 5.0\n",
    "    }\n",
    "    run_id = f\"run_{run}_repetition_{rep}\"\n",
    "    \n",
    "    # Display all rows\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        print(tsv_df[[\"accuracy\"]], sum(tsv_df['accuracy'], skipna=Tr) / 5.0)\n",
    "    \n",
    "    run_table_pd.loc[run_table_pd['__run_id'] == run_id, list(row.keys())] = list(row.values())\n",
    "        \n",
    "\n",
    "run_table_pd = run_table_pd.drop('energy', axis=1)\n",
    "run_table_pd.to_csv('out.csv')\n",
    "print('Finished, output to file out.csv')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38aeba59-7ae6-4a31-b8aa-0a03e90a6f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = tsv_df[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "708e4391-3b6f-4c11-ba35-94651169eba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>response_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1760502188</td>\n",
       "      <td>1760502190</td>\n",
       "      <td>Passage: Persian language -- Persian (/ˈpɜːrʒə...</td>\n",
       "      <td>Based on the given passage, it can be said t...</td>\n",
       "      <td>696</td>\n",
       "      <td>799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        start         end                                             prompt  \\\n",
       "0  1760502188  1760502190  Passage: Persian language -- Persian (/ˈpɜːrʒə...   \n",
       "\n",
       "                                            response  prompt_length  \\\n",
       "0    Based on the given passage, it can be said t...            696   \n",
       "\n",
       "   response_length  \n",
       "0              799  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eb8bcb-abfc-4bdf-a475-68516f40218e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
